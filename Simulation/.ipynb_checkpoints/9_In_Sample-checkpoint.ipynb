{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# Append the library path to PYTHONPATH, so library can be imported.\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "import shutil\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from library import common as cm\n",
    "from library import regression_aux as raux\n",
    "from library import in_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%run setup.py\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for: 1D\n",
      "Permutation flag: False\n",
      "VIX flag: False\n"
     ]
    }
   ],
   "source": [
    "print('Loading data for:', FREQ)\n",
    "print('Permutation flag:', PERMUTE)\n",
    "print('VIX flag:', VIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Normal data sets!\n",
      "\n",
      "Load and clean the training and validation data.\n",
      "Original data size is 526994\n",
      "We remove in-the-money samples. 264998 samples (50.28%) are removed. We have 49.72% of original data left, yielding a size of 261996.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.72% of original data left, yielding a size of 261996.\n",
      "We remove samples when S1 is not available. 998 samples (0.38%) are removed. We have 49.53% of original data left, yielding a size of 260998.\n",
      "\n",
      "\n",
      "====================\n",
      "Clean and load all Monte Carlo test data.\n",
      "\n",
      "Load Monte Carlo set 1\n",
      "We remove in-the-money samples. 72272 samples (50.83%) are removed. We have 49.17% of original data left, yielding a size of 69922.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.17% of original data left, yielding a size of 69922.\n",
      "We remove samples when S1 is not available. 1271 samples (1.82%) are removed. We have 48.28% of original data left, yielding a size of 68651.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 2\n",
      "We remove in-the-money samples. 68118 samples (51.12%) are removed. We have 48.88% of original data left, yielding a size of 65131.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 48.88% of original data left, yielding a size of 65131.\n",
      "We remove samples when S1 is not available. 1141 samples (1.75%) are removed. We have 48.02% of original data left, yielding a size of 63990.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 3\n",
      "We remove in-the-money samples. 58639 samples (50.00%) are removed. We have 50.00% of original data left, yielding a size of 58644.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 50.00% of original data left, yielding a size of 58644.\n",
      "We remove samples when S1 is not available. 796 samples (1.36%) are removed. We have 49.32% of original data left, yielding a size of 57848.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 4\n",
      "We remove in-the-money samples. 65780 samples (50.46%) are removed. We have 49.54% of original data left, yielding a size of 64571.\n",
      "We shrink moneyness range. 736 samples (1.14%) are removed. We have 48.97% of original data left, yielding a size of 63835.\n",
      "We remove samples when S1 is not available. 1108 samples (1.74%) are removed. We have 48.12% of original data left, yielding a size of 62727.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 5\n",
      "We remove in-the-money samples. 59294 samples (50.12%) are removed. We have 49.88% of original data left, yielding a size of 59020.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.88% of original data left, yielding a size of 59020.\n",
      "We remove samples when S1 is not available. 823 samples (1.39%) are removed. We have 49.19% of original data left, yielding a size of 58197.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 6\n",
      "We remove in-the-money samples. 59560 samples (49.90%) are removed. We have 50.10% of original data left, yielding a size of 59799.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 50.10% of original data left, yielding a size of 59799.\n",
      "We remove samples when S1 is not available. 821 samples (1.37%) are removed. We have 49.41% of original data left, yielding a size of 58978.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 7\n",
      "We remove in-the-money samples. 69001 samples (50.46%) are removed. We have 49.54% of original data left, yielding a size of 67734.\n",
      "We shrink moneyness range. 488 samples (0.72%) are removed. We have 49.18% of original data left, yielding a size of 67246.\n",
      "We remove samples when S1 is not available. 1304 samples (1.94%) are removed. We have 48.23% of original data left, yielding a size of 65942.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 8\n",
      "We remove in-the-money samples. 65560 samples (50.12%) are removed. We have 49.88% of original data left, yielding a size of 65237.\n",
      "We shrink moneyness range. 314 samples (0.48%) are removed. We have 49.64% of original data left, yielding a size of 64923.\n",
      "We remove samples when S1 is not available. 1192 samples (1.84%) are removed. We have 48.73% of original data left, yielding a size of 63731.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 9\n",
      "We remove in-the-money samples. 65366 samples (50.54%) are removed. We have 49.46% of original data left, yielding a size of 63958.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.46% of original data left, yielding a size of 63958.\n",
      "We remove samples when S1 is not available. 948 samples (1.48%) are removed. We have 48.72% of original data left, yielding a size of 63010.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 10\n",
      "We remove in-the-money samples. 65382 samples (49.84%) are removed. We have 50.16% of original data left, yielding a size of 65789.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 50.16% of original data left, yielding a size of 65789.\n",
      "We remove samples when S1 is not available. 1030 samples (1.57%) are removed. We have 49.37% of original data left, yielding a size of 64759.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 11\n",
      "We remove in-the-money samples. 59350 samples (50.07%) are removed. We have 49.93% of original data left, yielding a size of 59173.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.93% of original data left, yielding a size of 59173.\n",
      "We remove samples when S1 is not available. 866 samples (1.46%) are removed. We have 49.19% of original data left, yielding a size of 58307.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 12\n",
      "We remove in-the-money samples. 64011 samples (50.07%) are removed. We have 49.93% of original data left, yielding a size of 63840.\n",
      "We shrink moneyness range. 55 samples (0.09%) are removed. We have 49.89% of original data left, yielding a size of 63785.\n",
      "We remove samples when S1 is not available. 1126 samples (1.77%) are removed. We have 49.01% of original data left, yielding a size of 62659.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 13\n",
      "We remove in-the-money samples. 60216 samples (50.04%) are removed. We have 49.96% of original data left, yielding a size of 60123.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.96% of original data left, yielding a size of 60123.\n",
      "We remove samples when S1 is not available. 827 samples (1.38%) are removed. We have 49.27% of original data left, yielding a size of 59296.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 14\n",
      "We remove in-the-money samples. 59725 samples (49.92%) are removed. We have 50.08% of original data left, yielding a size of 59927.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 50.08% of original data left, yielding a size of 59927.\n",
      "We remove samples when S1 is not available. 816 samples (1.36%) are removed. We have 49.40% of original data left, yielding a size of 59111.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 15\n",
      "We remove in-the-money samples. 75897 samples (50.89%) are removed. We have 49.11% of original data left, yielding a size of 73247.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.11% of original data left, yielding a size of 73247.\n",
      "We remove samples when S1 is not available. 1062 samples (1.45%) are removed. We have 48.40% of original data left, yielding a size of 72185.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 16\n",
      "We remove in-the-money samples. 58766 samples (50.06%) are removed. We have 49.94% of original data left, yielding a size of 58615.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.94% of original data left, yielding a size of 58615.\n",
      "We remove samples when S1 is not available. 793 samples (1.35%) are removed. We have 49.26% of original data left, yielding a size of 57822.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 17\n",
      "We remove in-the-money samples. 65351 samples (50.03%) are removed. We have 49.97% of original data left, yielding a size of 65276.\n",
      "We shrink moneyness range. 413 samples (0.63%) are removed. We have 49.66% of original data left, yielding a size of 64863.\n",
      "We remove samples when S1 is not available. 1250 samples (1.93%) are removed. We have 48.70% of original data left, yielding a size of 63613.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 18\n",
      "We remove in-the-money samples. 61996 samples (50.09%) are removed. We have 49.91% of original data left, yielding a size of 61764.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.91% of original data left, yielding a size of 61764.\n",
      "We remove samples when S1 is not available. 866 samples (1.40%) are removed. We have 49.21% of original data left, yielding a size of 60898.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 19\n",
      "We remove in-the-money samples. 72219 samples (50.57%) are removed. We have 49.43% of original data left, yielding a size of 70587.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.43% of original data left, yielding a size of 70587.\n",
      "We remove samples when S1 is not available. 1477 samples (2.09%) are removed. We have 48.39% of original data left, yielding a size of 69110.\n",
      "\n",
      "\n",
      "Load Monte Carlo set 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We remove in-the-money samples. 60041 samples (50.27%) are removed. We have 49.73% of original data left, yielding a size of 59388.\n",
      "We shrink moneyness range. 0 samples (0.00%) are removed. We have 49.73% of original data left, yielding a size of 59388.\n",
      "We remove samples when S1 is not available. 815 samples (1.37%) are removed. We have 49.04% of original data left, yielding a size of 58573.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data must be after setup, because some of parameters are going to be overwritten.\n",
    "%run Load_Clean_aux.py normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=  f'FREQ={FREQ}_HALFMONEY=otm_MINM=0.8_MAXM=1.5_Permute=False_VIX=False'\n",
    "# make sure col name matches the setup res_dir\n",
    "assert col in res_dir     \n",
    "rows = ['Regression/No_Hedge', 'Regression/BS_Benchmark', 'Regression/Fixed_Constants',\n",
    "        'Regression/Delta_only', 'Regression/Vega_only', 'Regression/Gamma_only','Regression/Vanna_only',  \n",
    "        'Regression/Bias',\n",
    "        'Regression/Delta_Gamma', 'Regression/Delta_Vega',   'Regression/Delta_Vanna',\n",
    "        'Regression/Delta_Vega_Gamma', 'Regression/Delta_Vega_Vanna', 'Regression/Delta_Gamma_Vanna',   \n",
    "        'Regression/Delta_Vega_Gamma_Va', \n",
    "        'Regression/Hull_White', 'Regression/Hull_White_relaxed',\n",
    "        'Network/Normal_Feature', 'Network/Delta_Vega', 'Network/Delta_Vega_Vanna']\n",
    "\n",
    "sub_cols = ['Absolute', '%Change']\n",
    "cols_indices = pd.MultiIndex.from_product([[col], sub_cols], names=['setup', 'value'])\n",
    "df_call, df_put, df_both = [pd.DataFrame(index=rows, columns=cols_indices) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on C:\\Users\\Weiguan\\Dropbox\\Research\\DeepHedging\\Data\\Heston/Result/CONFIG=4/FREQ=1D_HALFMONEY=otm_MINM=0.8_MAXM=1.5_Permute=False_VIX=False/\n"
     ]
    }
   ],
   "source": [
    "print(f'Working on {res_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_windows(res):\n",
    "    \"\"\"\n",
    "    aggregate the MSE over windows by number of samples weighted average for calls and put separetely.\n",
    "    Also aggregate call and puts.\n",
    "    \"\"\" \n",
    "    call_mse, put_mse = [(res[(x, 'MSE')] * res[(x, 'num_samples')]).sum() / res[(x, 'num_samples')].sum() for x in ['0', '1']]\n",
    "    num_c, num_p = [res[(x, 'num_samples')].sum() for x in ['0', '1']]\n",
    "    both_mse = (call_mse * num_c + put_mse * num_p) / (num_c + num_p)\n",
    "    return call_mse, put_mse, both_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'vix': VIX, \n",
    "      'features': None, \n",
    "      'max_period': 0, \n",
    "      'sub_res': None,\n",
    "      'pnl_path': None,\n",
    "      'df': df_train,\n",
    "      'delta_coeff_1': False,\n",
    "      'agg_side': False,\n",
    "      'leverage': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zero hedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PERMUTE:\n",
    "    r_short = 'Regression/No_Hedge'\n",
    "   \n",
    "    zero = np.array([0.]*len(df_train))\n",
    "    zero = pd.Series(zero, index=df_train.index)\n",
    "    \n",
    "    res = in_sample.calc_in_sample_error_regression(known_delta=zero, **kwargs)\n",
    "    res = aggregate_windows(res)\n",
    "    df_call.loc[r_short, (col, 'Absolute')], df_put.loc[r_short, (col, 'Absolute')], df_both.loc[r_short, (col, 'Absolute')] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PERMUTE:\n",
    "    r_short = 'Regression/BS_Benchmark'\n",
    "    \n",
    "    res = in_sample.calc_in_sample_error_regression(known_delta=df_train['delta_bs'], **kwargs)\n",
    "    res = aggregate_windows(res)\n",
    "    df_call.loc[r_short, (col, 'Absolute')], df_put.loc[r_short, (col, 'Absolute')], df_both.loc[r_short, (col, 'Absolute')] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fixed constants: 0.9, 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PERMUTE:\n",
    "    r_short = 'Regression/Fixed_Constants'\n",
    "    \n",
    "    bl_c = df_train['cp_int'] == 0\n",
    "    delta = 0.9 * df_train['delta_bs']\n",
    "    delta[~bl_c] = 1.1 * df_train.loc[~bl_c, 'delta_bs']\n",
    "    \n",
    "    res = in_sample.calc_in_sample_error_regression(known_delta=delta, **kwargs)\n",
    "    res = aggregate_windows(res)\n",
    "    df_call.loc[r_short, (col, 'Absolute')], df_put.loc[r_short, (col, 'Absolute')], df_both.loc[r_short, (col, 'Absolute')] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All other regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regressions = [('Regression/Delta_only', ['delta_bs'], False),\n",
    "    ('Regression/Delta_Vega', ['delta_bs', 'vega_n'], False),\n",
    "    ('Regression/Delta_Gamma', ['delta_bs', 'gamma_n'], False),\n",
    "    ('Regression/Delta_Vanna', ['delta_bs', 'vanna_n'], False),\n",
    "    ('Regression/Delta_Gamma_Vanna', ['delta_bs', 'gamma_n', 'vanna_n'], False),\n",
    "    ('Regression/Delta_Vega_Gamma', ['delta_bs', 'vega_n', 'gamma_n'], False),\n",
    "    ('Regression/Delta_Vega_Vanna', ['delta_bs', 'vega_n', 'vanna_n'], False),\n",
    "    ('Regression/Delta_Vega_Gamma_Va', ['delta_bs', 'vega_n', 'gamma_n', 'vanna_n'], False),\n",
    "    ('Regression/Vega_only', ['vega_n'], True),\n",
    " ('Regression/Gamma_only', ['gamma_n'], True),\n",
    " ('Regression/Vanna_only', ['vanna_n'], True),\n",
    " ('Regression/Bias', ['bias'], True),\n",
    " ('Regression/Hull_White', ['vega_s', 'delta_vega_s', 'delta2_vega_s'], True),\n",
    "('Regression/Hull_White_relaxed', ['delta_bs', 'vega_s', 'delta_vega_s', 'delta2_vega_s'], False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['bias'] = 1.\n",
    "for row, features, delta_1 in all_regressions:\n",
    "    if not PERMUTE:\n",
    "\n",
    "        kwargs = {'vix': VIX, \n",
    "              'features': features, \n",
    "              'max_period': 0, \n",
    "              'sub_res': None,\n",
    "              'pnl_path': None,\n",
    "              'df': df_train,\n",
    "              'delta_coeff_1': delta_1,\n",
    "              'agg_side': False,\n",
    "              'leverage': False}\n",
    "\n",
    "        res = in_sample.calc_in_sample_error_regression(known_delta=None, **kwargs)\n",
    "        res = aggregate_windows(res)\n",
    "        df_call.loc[row, (col, 'Absolute')], df_put.loc[row, (col, 'Absolute')], df_both.loc[row, (col, 'Absolute')] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ANNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_fea = ['M0', 'tau0_implvol0']\n",
    "sub_res = res_dir + 'Network/Normal_Feature/'\n",
    "row = 'Network/Normal_Feature'\n",
    "use_fea = [x + '_t' for x in ori_fea] + ['cp_int']\n",
    "ckp_dir = sub_res + 'ckp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Weiguan\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Weiguan\\Anaconda3\\envs\\tfenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "res = in_sample.calc_in_sample_error_ann(df_train, ckp_dir, 0, ori_fea, use_fea, sim_data=True)\n",
    "res = aggregate_windows(res)\n",
    "df_call.loc[row, (col, 'Absolute')], df_put.loc[row, (col, 'Absolute')], df_both.loc[row, (col, 'Absolute')] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_fea = ['delta_bs', '1_over_sqrt_tau', 'vega_n']\n",
    "sub_res = res_dir + 'Network/Delta_Vega/'\n",
    "row = 'Network/Delta_Vega'\n",
    "use_fea = [x + '_t' for x in ori_fea] + ['cp_int']\n",
    "ckp_dir = sub_res + 'ckp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = in_sample.calc_in_sample_error_ann(df_train, ckp_dir, 0, ori_fea, use_fea, sim_data=True)\n",
    "res = aggregate_windows(res)\n",
    "df_call.loc[row, (col, 'Absolute')], df_put.loc[row, (col, 'Absolute')], df_both.loc[row, (col, 'Absolute')] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_fea = ['delta_bs', '1_over_sqrt_tau', 'vega_n', 'vanna_n']\n",
    "sub_res = res_dir + 'Network/Delta_Vega_Vanna/'\n",
    "row = 'Network/Delta_Vega_Vanna'\n",
    "use_fea = [x + '_t' for x in ori_fea] + ['cp_int']\n",
    "ckp_dir = sub_res + 'ckp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = in_sample.calc_in_sample_error_ann(df_train, ckp_dir, 0, ori_fea, use_fea,sim_data=True)\n",
    "res = aggregate_windows(res)\n",
    "df_call.loc[row, (col, 'Absolute')], df_put.loc[row, (col, 'Absolute')], df_both.loc[row, (col, 'Absolute')] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, name in zip([df_call, df_put, df_both], ['call', 'put', 'both']):\n",
    "    x[(col, '%Change')] = \\\n",
    "        ((x[(col, 'Absolute')] - x.loc['Regression/BS_Benchmark', (col, 'Absolute')]) \\\n",
    "        / x.loc['Regression/BS_Benchmark', (col, 'Absolute')]).astype(np.float).round(4) * 100\n",
    "    x[(col, 'Absolute')] = (x[(col, 'Absolute')] * 100.).astype(np.float).round(4)\n",
    "    \n",
    "    x.to_csv(f'{DATA_DIR}Result/in_sample_{name}_mse_{FREQ}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
