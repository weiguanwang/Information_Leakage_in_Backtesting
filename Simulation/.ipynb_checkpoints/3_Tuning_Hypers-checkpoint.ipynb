{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Append the library path to PYTHONPATH, so library can be imported.\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from library import plot\n",
    "from library import network as nw\n",
    "from library import common as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.py\n",
    "%run Load_Clean_aux.py tune\n",
    "\n",
    "seed = 666\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FEATURE_SET == 'normal_feature':\n",
    "    ori_fea = ['M0', 'tau0_implvol0']\n",
    "    sub_res = res_dir + 'Network/Normal_Feature/TuneHypers/'\n",
    "\n",
    "if FEATURE_SET == 'delta_vega':\n",
    "    ori_fea = ['delta_bs', '1_over_sqrt_tau', 'vega_n']\n",
    "    sub_res = res_dir + 'Network/Delta_Vega/TuneHypers/'\n",
    "\n",
    "if VIX:\n",
    "    ori_fea += ['fake_vix']\n",
    "\n",
    "os.makedirs(sub_res, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_train.loc[df_train['period0'] == 1].copy()\n",
    "df_train = df_train.loc[df_train['period0'] == 0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 2: Standardize features\n",
    "The training and validation set are standardized, and the resulting scaler shall be passed to standardize each Monte Carlo set later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fea = [x + '_t' for x in ori_fea] + ['cp_int']\n",
    "\n",
    "scaler = StandardScaler().fit(X=df_train[ori_fea])\n",
    "df_train, df_val = nw.standardize_feature([df_train, df_val], scaler, ori_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 3: Specify a candidate set\n",
    "We need to specify a set of candidate hyperparameters. Each candidate will be used to train a new network for a specified number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {\n",
    "    'nodes_per_layer': (30, 30),\n",
    "    'reg_alpha': 1e-4,\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 300,\n",
    "    'outact': 'linear'\n",
    "}\n",
    "lab_tune = 'reg_alpha'\n",
    "value_set = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "num_run = 5 # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 4: Training step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for value in value_set:\n",
    "    # If you want to tune other hyper apart from alpha, \n",
    "    # change key name and directory name of the next two lines.\n",
    "    hypers[lab_tune] = value\n",
    "    alpha_dir = sub_res + f'para={value:.0e}/'\n",
    "    \n",
    "    alpha_dir_dict = {\n",
    "        'ckp': alpha_dir + 'ckp/',\n",
    "        'history': alpha_dir + 'history/',\n",
    "        'metrics': alpha_dir + 'metrics/',\n",
    "        'plot': alpha_dir + 'plot/'\n",
    "    }\n",
    "    for key, value in alpha_dir_dict.items():\n",
    "        os.makedirs(value, exist_ok=True)\n",
    "    \n",
    "    # for each value, we train a (new) network multiple times.\n",
    "    for i in range(num_run):   \n",
    "        \"\"\"\n",
    "        Here, each checkpoint, history, and metrics corresponds to each run.\n",
    "        \"\"\"        \n",
    "        # for each iteration, we record its performance on each of MC set.\n",
    "        df_metrics = pd.DataFrame(index=range(NUM_TEST), columns=['BS', 'NN'])\n",
    "        \n",
    "        sub_res_paths = {\n",
    "            'ckp': alpha_dir_dict['ckp'] + f'bestcp{i}.h5',\n",
    "            'history': alpha_dir_dict['history'] + f'history{i}.csv',\n",
    "            'plot': alpha_dir_dict['plot'] + f'losscurve{i}.png',\n",
    "            'metrics': alpha_dir_dict['metrics'] + f'metrics{i}.csv'\n",
    "        }\n",
    "        history = nw.train_net_core(df_train, df_val, use_fea, hypers, sub_res_paths)\n",
    "        nw.plot_history(history, sub_res_paths['plot'], df_train, df_val)\n",
    "        \n",
    "        \"\"\"\n",
    "        Each train is tested on many Monte Carlo sets.\n",
    "        \"\"\"\n",
    "        for j in range(NUM_TEST):\n",
    "            df_test = mc_sets[j].copy()\n",
    "            [df_test] = nw.standardize_feature([df_test], scaler, ori_fea)\n",
    "            \n",
    "            delta_nn = nw.test_net_core(df_test, use_fea, sub_res_paths)\n",
    "            \n",
    "            \"\"\"\n",
    "            We calculate NN pnl and BS pnl.\n",
    "            \"\"\"\n",
    "            pnl_nn = cm.calc_pnl(df_test, delta_nn)\n",
    "            pnl_bs = cm.calc_pnl(df_test, df_test['delta_bs'])\n",
    "            \n",
    "            df_metrics.loc[j, 'NN'] = (pnl_nn**2).mean()\n",
    "            df_metrics.loc[j, 'BS'] = (pnl_bs**2).mean()      \n",
    "        \n",
    "        df_metrics.to_csv(sub_res_paths['metrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize tuning results\n",
    "This section can be run independent of the above one, if the directory paths are given properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_run = 5\n",
    "value_set = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_summary = pd.DataFrame(\n",
    "    index=range(num_run), \n",
    "    columns=['BS'] + [f'para={v:.0e}' for v in value_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in value_set:\n",
    "    metrics_folder = sub_res + f'para={value:.0e}/metrics/'\n",
    "    \n",
    "    for i in range(num_run):\n",
    "        df_metrics = pd.read_csv(metrics_folder + f'metrics{i}.csv', index_col=0)\n",
    "        \"\"\"\n",
    "        'BS' errors do not change, whatever the alpha is.\n",
    "        We take the average over all test sets for each run.\n",
    "        \"\"\"\n",
    "        df_metrics_summary.loc[i, 'BS'] = df_metrics.mean()['BS'] \n",
    "        df_metrics_summary.loc[i, f'para={value:.0e}'] = df_metrics.mean()['NN']\n",
    "\n",
    "df_metrics_summary = df_metrics_summary.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This summary table shows the average test metric over all the Monte Carlo data sets, for different hyperparamters and many runnings of network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_summary.to_csv(f'{sub_res}individual_mc_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_summary.describe().to_csv(f'{sub_res}summary_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_summary.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results\n",
    "Run this section, if you want to save all related checkpoint, history and plots permanently, so that they will not be covered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy data setup file from the clean data folder, and then append network setup.\n",
    "shutil.copy('setup.py', sub_res)\n",
    "\n",
    "with open(f'{sub_res}tuning-setting.txt', 'w') as file:\n",
    "    file.write('The following is TUNE setup.\\n')\n",
    "    file.write(f'Date and time = {datetime.datetime.now()}\\n')\n",
    "    for n, x in [\n",
    "        ('Random seed', seed),\n",
    "        ('Features used', use_fea),\n",
    "        ('Hypers', hypers),\n",
    "        ('Value set to tune from', value_set),\n",
    "        ('Number of iterations', num_run)\n",
    "    ]:\n",
    "        file.write(f'{n} = {x}\\n') \n",
    "    file.write(f'{lab_tune} is being tuned.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
